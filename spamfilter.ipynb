{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spamfilter.ipynb",
      "provenance": [],
      "mount_file_id": "1phoM71itRzb4GJg_mHbWEFfZOpj87JiZ",
      "authorship_tag": "ABX9TyM6jMFtrcWnFTioptYLLnrL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akanksha0911/Spamfilterassign/blob/main/spamfilter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DDu6APviawG"
      },
      "source": [
        "Import the libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nAn1t1DNsFf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3DLEFOgdEXJ"
      },
      "source": [
        "Created a CSV file with all the given documents in assignment and read the file here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QtFsAoFmN4MK",
        "outputId": "a43fad8e-5865-4d5e-d93c-8bd2af26541e"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/SpamDoc - Sheet1.csv\")\n",
        "df.head()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Free -Coupons for next movie. The above links ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Free -Coupons for next movie. The above links ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Our records indicate your Pension is under per...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I know that's an incredible statement, but bea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dear recipient, Avangar Technologies announces...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  Free -Coupons for next movie. The above links ...     1\n",
              "1  Free -Coupons for next movie. The above links ...     1\n",
              "2  Our records indicate your Pension is under per...     1\n",
              "3  I know that's an incredible statement, but bea...     1\n",
              "4  Dear recipient, Avangar Technologies announces...     1"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdMurhg4dMyQ"
      },
      "source": [
        "there are only Spams so the 1 is assigned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGFMRsWGOG62",
        "outputId": "9a1b42ab-3686-4cc8-8b3c-da0bc056977f"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCex_c2XOKnA",
        "outputId": "176eaf48-594a-45a9-af8c-4b0592ad98b8"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'spam'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SuAtXzqOOKi",
        "outputId": "b13582c9-47b8-43bc-962d-126ff31c826c"
      },
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "print(df.shape)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clBBsE-lOyMg",
        "outputId": "8df79696-a647-45e5-a0b3-43796162fa3b"
      },
      "source": [
        "# download the stopwords package\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKZ8WQnHeVo5"
      },
      "source": [
        "function to clean the text and return the tokens. The cleaning of the text can be done by first removing punctuations and then removing the useless words also known as stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_7CkLwYO8YC",
        "outputId": "4cdade27-aeec-4bfb-a77c-ec835b804f89"
      },
      "source": [
        "#Tokenization (a list of tokens), will be used as the analyzer\n",
        "\n",
        "def token(text):\n",
        "\n",
        "  #1 Remove Punctuationa\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "\n",
        "#2 Remove Stop Words\n",
        "    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
        "    return clean\n",
        "\n",
        "\n",
        "# to show the tokenization\n",
        "df['text'].head().apply(token)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [Free, Coupons, next, movie, links, take, stra...\n",
              "2    [records, indicate, Pension, performing, see, ...\n",
              "3    [know, thats, incredible, statement, bear, exp...\n",
              "4    [Dear, recipient, Avangar, Technologies, annou...\n",
              "5    [Enter, win, 25000, get, Free, Hotel, Night, c...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiKaSZqiUwPK"
      },
      "source": [
        "Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5R8yOdVPEcd"
      },
      "source": [
        "# Now convert the text into a matrix of token counts :\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vector = CountVectorizer(analyzer=token).fit_transform(df['text'])"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4LCQbOdPbQo",
        "outputId": "5eb4266c-7528-45ea-991e-3cdf26af81dc"
      },
      "source": [
        "vector.shape"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 197)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-sTG3zSZg6V",
        "outputId": "80115b61-2c1b-4fa7-aed7-ed0b517aa464"
      },
      "source": [
        "print(vector)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 22)\t1\n",
            "  (0, 14)\t1\n",
            "  (0, 131)\t1\n",
            "  (0, 128)\t1\n",
            "  (0, 120)\t1\n",
            "  (0, 178)\t1\n",
            "  (0, 176)\t1\n",
            "  (0, 144)\t1\n",
            "  (0, 171)\t1\n",
            "  (0, 110)\t1\n",
            "  (0, 167)\t1\n",
            "  (0, 136)\t1\n",
            "  (0, 53)\t1\n",
            "  (0, 47)\t1\n",
            "  (0, 187)\t1\n",
            "  (0, 25)\t1\n",
            "  (0, 42)\t1\n",
            "  (0, 8)\t1\n",
            "  (0, 188)\t1\n",
            "  (1, 167)\t1\n",
            "  (1, 155)\t1\n",
            "  (1, 109)\t1\n",
            "  (1, 36)\t1\n",
            "  (1, 148)\t1\n",
            "  (1, 102)\t1\n",
            "  :\t:\n",
            "  (4, 75)\t1\n",
            "  (4, 12)\t1\n",
            "  (4, 11)\t1\n",
            "  (4, 43)\t1\n",
            "  (4, 74)\t1\n",
            "  (4, 2)\t1\n",
            "  (4, 169)\t1\n",
            "  (4, 31)\t1\n",
            "  (4, 175)\t1\n",
            "  (4, 137)\t1\n",
            "  (4, 72)\t1\n",
            "  (4, 24)\t1\n",
            "  (4, 66)\t1\n",
            "  (4, 76)\t1\n",
            "  (4, 183)\t1\n",
            "  (4, 57)\t1\n",
            "  (4, 1)\t1\n",
            "  (4, 151)\t1\n",
            "  (4, 35)\t1\n",
            "  (4, 67)\t1\n",
            "  (4, 129)\t1\n",
            "  (4, 149)\t1\n",
            "  (4, 63)\t1\n",
            "  (4, 54)\t1\n",
            "  (4, 48)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwljjy0DPKx2"
      },
      "source": [
        "Now we need to split the data into training and testing sets, and then we will use this one row of data for testing to make our prediction later on and test to see if the prediction matches with the actual value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlB8Kac9PMDg",
        "outputId": "3944ff75-c6fd-4bbd-e570-c8cdc887d9dc"
      },
      "source": [
        "#split the data into 70% training and 30% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(vector, df['spam'], test_size=0.30, random_state=0)\n",
        "# To see the shape of the data\n",
        "print(vector.shape)\n",
        "print(xtrain.shape)\n",
        "print(xtest.shape)\n"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 197)\n",
            "(3, 197)\n",
            "(2, 197)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5JYfkmTWcQX"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "\n",
        "X_train_transformed = tfidf_transformer.fit(xtrain)\n",
        "\n",
        "X_test_transformed = tfidf_transformer.fit(xtest)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No5owB2tXzn_",
        "outputId": "414c6f00-2c9e-4f6b-fd0c-7802befac5a7"
      },
      "source": [
        "print(X_train_transformed)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqIP0TjFP8Kp"
      },
      "source": [
        "Now we need to create and train the Multinomial Naive Bayes classifier which is suitable for classification with discrete features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmpS5KskP9Wp"
      },
      "source": [
        "# create and train the Naive Bayes Classifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB().fit(xtrain, ytrain)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaFsGiM2QSJC"
      },
      "source": [
        "**To see the classifiers prediction and actual values on the data set :**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R-pNPfUQWEw",
        "outputId": "ed73b386-7075-4931-bff5-06f4adf3024e"
      },
      "source": [
        "print(classifier.predict(xtrain))\n",
        "print(ytrain.values)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1]\n",
            "[1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x-_o1NmQdiu"
      },
      "source": [
        "Now let’s see how well our model performed by evaluating the Naive Bayes classifier and the report, confusion matrix & accuracy score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gydMCxqUQekk",
        "outputId": "416ca4a3-7180-496e-b632-15863faaa696"
      },
      "source": [
        "# Evaluating the model on the training data set\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "pred = classifier.predict(xtrain)\n",
        "print(classification_report(ytrain, pred))\n",
        "print()\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\n",
        "print(\"Accuracy: \\n\", accuracy_score(ytrain, pred))"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3]]\n",
            "Accuracy: \n",
            " 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ch7ExrARajB",
        "outputId": "a5a8b7b5-dd8c-492e-d650-bc6f4a6fc7d1"
      },
      "source": [
        "#print the predictions\n",
        "print(classifier.predict(xtest))\n",
        "#print the actual values\n",
        "print(ytest.values)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1]\n",
            "[1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd9pc88bgmg6"
      },
      "source": [
        "It has predicted on test data accurately , 1 = spam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7QcGsllRuiG"
      },
      "source": [
        "let’s evaluate the model on the test data set \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkMlga5-RlMN",
        "outputId": "d8b4f865-e57e-41de-bbc2-716f5686de5b"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "pred = classifier.predict(xtest)\n",
        "print(classification_report(ytest, pred))\n",
        "print()\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\n",
        "print(\"Accuracy: \\n\", accuracy_score(ytest, pred))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "\n",
            "Confusion Matrix: \n",
            " [[2]]\n",
            "Accuracy: \n",
            " 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5c6F0DhR3wb"
      },
      "source": [
        "The classifier accurately identified the email messages as spam or not spam with 100% accuracy on the test data.\n",
        "\n"
      ]
    }
  ]
}